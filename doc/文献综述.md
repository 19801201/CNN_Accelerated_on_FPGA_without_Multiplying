# 文献综述
ShiftCNN: Generalized Low-Precision Architecture for Inference of Convolutional Neural Networks

一个利用低精度和量化技术实现的神经网络压缩与加速方案。 个人认为，这是低精度量化方面少有的具有一定工程可行性的方案(虽然文中没有给出详细的模型大小速度方面的指标)。

ShiftAddNet: A Hardware-Inspired Deep Network

本文借鉴硬件开发过程中的相关经验，提出一种ShiftAddNet，采用加法和位移操作来代替深度学习神经网络中的乘法运算，这种网络能够在不损害标准DNNs表达能力的同时，实现低功耗地推理和训练。

[ShiftAddNet 文章地址](/doc/articles/ShiftAddNet.pdf)

[ShiftAddNet 代码地址](https://github.com/RICE-EIC/ShiftAddNet)

AdderNet and Its Minimalist Hardware Design for Energy-Efficient Artificial Intelligence

CNN已经被广泛地应用于各种机器学习任务，但由于其计算较为密集且能源消耗较高，很难直接应用于资源受限的环境中，如：物联网设备或者智能手机上。为了降低计算复杂度，减少能源消耗，本文提出了AdderNet；使用加法器替代了CNN中的卷积运算。该网络在降低功耗，提高资源利用率的同时也保证了其运算速度。

[AdderNet 文章地址](/doc/articles/AdderNet.pdf)

[AdderNet 代码地址暂未提供]

DeepShift: Towards Multiplication-Less Neural Networks

传统CNN网络的高计算量、高功耗是边缘计算平台模型部署的主要瓶颈。本文使用卷积移位和全连接位移运算代替训练和推理过程中传统CNN网络的乘法运算；在保证精度的同时降低延迟。

[DeepShift 文章地址](/doc/articles/DeepShift.pdf)

[DeepShift 代码地址](https://github.com/mostafaelhoushi/DeepShift)


S3: Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks

本文针对移位神经网络提出一种新的训练方法，力图解决移位神经网络中由权重初始不合适化带来的梯度消失、权重冻结等现象造成的性能下降问题。


[Sign-Sparse-Shift Reparametrization 文章地址](/doc/articles/Sign_Sparse_Shift.pdf)

[Sign-Sparse-Shift Reparametrization 代码地址 暂未提供]




